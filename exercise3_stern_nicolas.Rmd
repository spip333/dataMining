---
title: "Exercise_3_stern_nicolas"
author: "Nicolas Stern"
date: "23 mars 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup, Libraries
```{r}
library("e1071")
library(class)
``` 

# Daten laden
Das setup setzt voraus, das das Skript im Arbeitsverzeichnis abgelegt ist, und dass die *.csv Datein mit den Daten im selben Verzeichnis auch vorhanden ist.

```{r}
mnist_matrix_full = read.csv( 'MNIST.csv' ) 
mnist_matrix = mnist_matrix_full[1:1000,]
```

# Fragen / Antworten über die Daten

a. Wieviele Bilder sind in der Matrix mnist_matrix encodiert

```{r}
dim(mnist_matrix) 
```

=> Die Matrix mit der Daten ist 42000 Zeilen Lang, jede Zeile enthält ein Bild.

b. Da es sich um einen Supervised Machine Learning task handelt muss ein Label (Target Variable) bereitgestellt sein - welche Spalte der Matrix enthält das Label?

=> Die 1. Spalte der Matrix enthält das Label. Der Wertebereich der 1. Spalte wird wie folgt  ersichtlich: 

```{r}
sort(unique(mnist_matrix[,1])) 
```

c. Wieviele Pixel haben die Bilder?

=> jede Zeile hat 785 Spalten. 1. Spalte ist der Label, die restliche 784 Spalten enthalten die Pixel-Werte. Jedes Bild hat also 784 Pixels.

d. Wie hoch/breit sind die Bilder?

=> Jedes Bild kann als 28 * 28 Quadrat ausgedruckt werden: (28 X 28 = 784) 

# Print die ersten 10 Bilder mit dem Label

```{r}
par( mfrow = c(10, 10), mai = c(0,0,0,0)) 

for(i in 1:10){ 
  y = as.matrix(mnist_matrix[i, 2:785])
  dim(y) = c(28, 28) 
  image( y[,nrow(y):1], axes = FALSE, col = gray(255:0 / 255))
  text( 0.2, 0, mnist_matrix[i,1], cex = 3, col = 2, pos = c(3,4)) 
} 
```

# Daten Vorbereiten für Klassifizierung

Die Daten werden in einer Training Datenmenge und einer Test Datenmenge aufgetrennt. Die Training Datenmenge enthält 10% der Totalen Datenmenge.

```{r}
ind = sample(2, nrow(mnist_matrix), replace=TRUE, prob=c(0.1, 0.9))
train_data_with_label = mnist_matrix[ind==1,]
test_data_with_label = mnist_matrix[ind==2,]

train_data = train_data_with_label[-1]
test_data = test_data_with_label[-1]

train_labels = factor(train_data_with_label[,1])
test_labels = factor(test_data_with_label[,1])
```


# KNN
```{r}
pred_knn = knn(train = train_data, 
               test = test_data, 
               cl= train_labels, 
               k = 10, 
               prob=TRUE) 

table(pred_knn, test_labels) 

truth_vector_validate_knn = pred_knn == test_labels
good_knn = length(truth_vector_validate_knn[truth_vector_validate_knn==TRUE])
bad_knn = length(truth_vector_validate_knn[truth_vector_validate_knn==FALSE])
bad_knn / (good_knn+bad_knn)

```

# naive-bayes
```{r}
m = naiveBayes(train_data, train_labels)
pred_nb = predict(m, test_data)
table(test_labels, pred_nb)

truth_vector_validate_nb = pred_nb == test_labels
good_nb = length(truth_vector_validate_nb[truth_vector_validate_nb==TRUE])
bad_nb = length(truth_vector_validate_nb[truth_vector_validate_nb==FALSE])
bad_nb/(good_nb+bad_nb)

```




